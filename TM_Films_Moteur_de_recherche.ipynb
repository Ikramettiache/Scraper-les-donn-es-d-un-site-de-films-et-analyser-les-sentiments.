{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TM_Films_Moteur de recherche.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT50DpJjb9tF"
      },
      "source": [
        "########## Monter mon drive sur colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RdNRi_wcBPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2910ea0b-6306-4b73-9de0-51674764423a"
      },
      "source": [
        "#Importation des packages\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_md\n",
        "import spacy\n",
        "import fr_core_news_md\n",
        "!pip install -U textblob\n",
        "!pip install -U textblob-fr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Collecting fr_core_news_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.2.5-cp37-none-any.whl size=90338490 sha256=c6c6d82839eecb5a661ae1709fcb97ce0c17b69b1f19754342fd23068d576335\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s8qdk5lz/wheels/c6/18/b6/f628642acc7872a53cf81269dd1c394d96da69564ccfac5425\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n",
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Collecting textblob-fr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/53/1d532ed522e561bc75e78e5c1920aba52f574847339462780cd060f2e607/textblob_fr-0.2.0-py2.py3-none-any.whl (561kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: textblob>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from textblob-fr) (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob>=0.8.0->textblob-fr) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob>=0.8.0->textblob-fr) (1.15.0)\n",
            "Installing collected packages: textblob-fr\n",
            "Successfully installed textblob-fr-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#l'URL du page index\n",
        "master=\"http://www.allocine.fr\"\n",
        "pages_s=[]\n",
        "#Recupere les ahref de toutes les films d'un genre spécifié\n",
        "for i in range(10):\n",
        "   index=\"http://www.allocine.fr/series-tv/genre-13030/?page=\"+str(i+1)\n",
        "   p=requests.get(index)\n",
        "   script= html.fromstring(p.content)\n",
        "   pages_s.extend(script.xpath('//a[@class=\"meta-title-link\"]/@href'))\n",
        "\n",
        "\n",
        "titres_s=[]\n",
        "avis_s=[]\n",
        "rate_s=[]\n",
        "\n",
        "#boucler sur tous les films et recuperer le titre les avis et les scores de chaque film\n",
        "for i in pages_s:\n",
        "  index=master+i\n",
        "  p=requests.get(index)\n",
        "  script= html.fromstring(p.content)\n",
        "  titres =(script.xpath('//div[@class=\"titlebar-title titlebar-title-lg\"]//text()')[0])\n",
        "  avis = script.xpath('//div[@class=\"content-txt review-card-content\"]/text()')\n",
        "  rate = script.xpath('//div[@class=\"stareval stareval-medium stareval-theme-default\"]/span[@class=\"stareval-note\"]/text()')\n",
        "  for j,k in zip(avis,rate):\n",
        "    titres_s.append(titres)\n",
        "    avis_s.append(j)\n",
        "    rate_s.append(k)\n",
        "\n",
        "#Sauvegarder le resultat de Scrapping dans une dataframe\n",
        "d={\"Titre\":titres_s,\"Avis\":avis_s,\"Score\":rate_s}\n",
        "df=pd.DataFrame(d)\n",
        "df.to_csv('/content/drive/My Drive/TM/Avis_Medicale.csv' , encoding = \"UTF-8\",sep =\";\" , index = False)"
      ],
      "metadata": {
        "id": "DQ0AjX3_aLVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1HPWtkQdMFS"
      },
      "source": [
        "#Enlever les Stop Word\n",
        "def remove_stop_words(corpus):\n",
        "    french_stop_words = stopwords.words('french')\n",
        "    word_tokens = word_tokenize(corpus) \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in french_stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wBML6YWdm_q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3cffa9ad-922a-4a31-9056-7d01be452831"
      },
      "source": [
        "#Stemming\n",
        "\"\"\"\n",
        "def get_stemmed_text(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    stem_sentence=[]\n",
        "    porter=PorterStemmer()\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "    return ' '.join(stem_sentence)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_stemmed_text(sentence):\\n    token_words=word_tokenize(sentence)\\n    stem_sentence=[]\\n    porter=PorterStemmer()\\n    for word in token_words:\\n        stem_sentence.append(porter.stem(word))\\n    return ' '.join(stem_sentence)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTLzmtehd_6v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "91853e30-be4e-49bc-ca7a-8c5bb76d6b2a"
      },
      "source": [
        "#Lemmatization (n'est pas fiable)\n",
        "\"\"\"\n",
        "def get_lemmatized_text(corpus):\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()    \n",
        "    token_words=word_tokenize(corpus)\n",
        "    lem_sentence=[]\n",
        "    for w in token_words:\n",
        "        lem_sentence.append(wordnet_lemmatizer.lemmatize(w))\n",
        "    return ' '.join(lem_sentence)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_lemmatized_text(corpus):\\n    wordnet_lemmatizer = WordNetLemmatizer()    \\n    token_words=word_tokenize(corpus)\\n    lem_sentence=[]\\n    for w in token_words:\\n        lem_sentence.append(wordnet_lemmatizer.lemmatize(w))\\n    return ' '.join(lem_sentence)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9sGq9xdePuI"
      },
      "source": [
        "#Lematization avec fr_core_news_md fiable que WordNetLemmatizer\n",
        "nlp = fr_core_news_md.load()\n",
        "def get_lemmatized_text(corpus):\n",
        "    filtered_sentence = []\n",
        "    t= nlp(u\"\"+corpus)\n",
        "    for i in t:\n",
        "       filtered_sentence.append(i.lemma_)\n",
        "    return ' '.join(filtered_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUMMU4nlkx7X"
      },
      "source": [
        "#enlever les ponctuation et les nombres\n",
        "def get_unpuncuated_text(corpus):\n",
        "    words = nltk.word_tokenize(corpus)\n",
        "    words=[word.lower() for word in words if word.isalpha()]\n",
        "    return ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnuiQHATk6F-"
      },
      "source": [
        "#Preprocessing complet\n",
        "def preprocessing(corpus):\n",
        "  corpus= remove_stop_words(corpus)\n",
        "  corpus=get_lemmatized_text(corpus)\n",
        "  corpus =get_unpuncuated_text(corpus)\n",
        "  return corpus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbmrynGXYHj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e8fb7be9-0545-4505-8cad-ecc273c9e759"
      },
      "source": [
        "# sample text for performing tokenization\n",
        "text = \"In Brazil they drive on the right-hand side of the road. Brazil has a large coastline on the eastern side of South America\"\n",
        "# importing word_tokenize from nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Passing the string text into word tokenize for breaking the sentences\n",
        "token = word_tokenize(text)\n",
        "token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'Brazil',\n",
              " 'they',\n",
              " 'drive',\n",
              " 'on',\n",
              " 'the',\n",
              " 'right-hand',\n",
              " 'side',\n",
              " 'of',\n",
              " 'the',\n",
              " 'road',\n",
              " '.',\n",
              " 'Brazil',\n",
              " 'has',\n",
              " 'a',\n",
              " 'large',\n",
              " 'coastline',\n",
              " 'on',\n",
              " 'the',\n",
              " 'eastern',\n",
              " 'side',\n",
              " 'of',\n",
              " 'South',\n",
              " 'America']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf-awthtb4qN"
      },
      "source": [
        "#Preprocessing sur les description\n",
        "desc_clean=[]\n",
        "for i in desc:\n",
        "  desc_clean.append(preprocessing(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k9BCDMvE6LI"
      },
      "source": [
        "#Preprocessing sur les avis\n",
        "def clean_Avis(a):\n",
        "   c=[]\n",
        "   for i in a:\n",
        "      x=i.replace(\"\\n\",\"\")\n",
        "      for j in range(20):\n",
        "          if \"  \" in x:\n",
        "               x=x.replace(\"  \",\"\")\n",
        "      c.append(x)\n",
        "   for k in range(0,len(c)):\n",
        "        if c[k] == \"\":\n",
        "          c[k]=None\n",
        "          \n",
        "   return c \n",
        "clean_avis=clean_Avis(avis)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNnlJZl105iq"
      },
      "source": [
        "Recherche par titre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY_fvR3C04fp"
      },
      "source": [
        "#Grouper les avis (une fct qui retourne les avis d'un film donné ordonné par score)\n",
        "def grouper_par_score(t):\n",
        "  d={\"Titre\":titreR,\"Avis\":clean_avis,\"Score\":rating}\n",
        "  a= pd.DataFrame(d) \n",
        "  a= a[a[\"Titre\"] == t]\n",
        "  a=a.dropna(axis=0)\n",
        "  a=a.sort_values(by=['Score'], ascending=False)\n",
        "  return a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqa7U7yQEzu1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "42080588-b1f5-4d9d-9716-f040149edbcd"
      },
      "source": [
        "#Recherche par titre (une fct qui retourne toute les infos d'un film donné)\n",
        "def recherche_par_titre(t):\n",
        "  for i in titre:\n",
        "    if i == t:\n",
        "      print(\"Titre :\"+t)\n",
        "      print(\"Genre :\"+genre[titre.index(i)])\n",
        "      print(\"Description :\"+desc[titre.index(i)])\n",
        "      print(\"Avis :\")\n",
        "      print(grouper_par_score(t))\n",
        "recherche_par_titre(\"Titans\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Titre :Titans\n",
            "Genre :Action\n",
            "Description :[\"Dick Grayson, alias Robin,\\xa0sort de l’ombre pour devenir le chef de file d’un groupe de nouveaux héros constitué notamment de Starfire, Raven ou encore Hawk et Dove. Peu à peu, il\\xa0s'affranchit de Batman pour devenir Nightwing....\"]\n",
            "Avis :\n",
            "    Titre                                               Avis Score\n",
            "1  Titans  Bon début sur cette série mais flop total sur ...   4,0\n",
            "0  Titans  Cette série est une véritable déception ! A pa...   3,2\n",
            "2  Titans  Vu les deux premiers épisodes, il est certes p...   1,5\n",
            "5  Titans  je n'ai pas accroché à cette série car ce n'es...   0,5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpyJv5pl2Lb1"
      },
      "source": [
        "#Analyser les sentiments des avis\n",
        "def analyser_avis():\n",
        "  from textblob import TextBlob\n",
        "  from textblob import Blobber\n",
        "  from textblob_fr import PatternTagger, PatternAnalyzer\n",
        "  tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "  res=[]\n",
        "  for i in avis:\n",
        "      text = tb(u\"\"+i)\n",
        "      res.append(text.sentiment[0])\n",
        "  ress=[]\n",
        "  for i in range(0,len(res)):\n",
        "      res[i]=round(res[i],2)\n",
        "      if res[i] > 0:\n",
        "        ress.append(str(\"Positive de \"+ str(int(res[i]*100))+ \"%\"))\n",
        "      elif res[i] == 0:\n",
        "        ress.append(str(\"Neutre\"))\n",
        "      else :\n",
        "        ress.append(str(\"Négative de \"+ str(int(res[i]*100*-1))+ \"%\"))\n",
        "  return [res,ress]\n",
        "\n",
        "#Grouper les avis (une fct qui retourne les avis d'un film donné ordonné par analyse de sens) \n",
        "def grouper_par_avis(t):\n",
        "  av=analyser_avis()\n",
        "  d={\"Titre\":titreR , \"Avis\":clean_avis , \"Sentiment\": av[1] , \"ordre\": av[0]}\n",
        "  a= pd.DataFrame(d) \n",
        "  a= a[a[\"Titre\"] == t]\n",
        "  a=a.dropna(axis=0)\n",
        "  a=a.sort_values(by=[\"ordre\"], ascending=False)\n",
        "  a=a.drop([\"ordre\"], axis='columns')\n",
        "  return a\n",
        "\n",
        "#Recherche par titre (une fct qui retourne toute les infos d'un film donné)\n",
        "def recherche_par_titre_AS(t):\n",
        "  for i in titre:\n",
        "    if i == t:\n",
        "      print(\"Titre :\"+t)\n",
        "      print(\"Genre :\"+genre[titre.index(i)])\n",
        "      print(\"Description :\"+desc[titre.index(i)])\n",
        "      print(\"Avis :\")\n",
        "      #Vous trouverez ici la fonction grouper et analyser par avis\n",
        "      print(grouper_par_avis(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ8ZprgA4pNv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "edd9b44b-bdc0-46ac-c57b-8cd967247981"
      },
      "source": [
        "recherche_par_titre_AS(\"Titans\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Titre :Titans\n",
            "Genre :Action\n",
            "Description :[\"Dick Grayson, alias Robin,\\xa0sort de l’ombre pour devenir le chef de file d’un groupe de nouveaux héros constitué notamment de Starfire, Raven ou encore Hawk et Dove. Peu à peu, il\\xa0s'affranchit de Batman pour devenir Nightwing....\"]\n",
            "Avis :\n",
            "    Titre                                               Avis        Sentiment\n",
            "1  Titans  Bon début sur cette série mais flop total sur ...  Positive de 21%\n",
            "2  Titans  Vu les deux premiers épisodes, il est certes p...   Négative de 2%\n",
            "0  Titans  Cette série est une véritable déception ! A pa...   Négative de 6%\n",
            "5  Titans  je n'ai pas accroché à cette série car ce n'es...  Négative de 15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwTXRCnW0pM4"
      },
      "source": [
        "Recherche par description  en utilisant cosine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N92yD8ELelu-"
      },
      "source": [
        "#L'indice de similarité cosine (avec le resultat de TfIdf) \n",
        "#une fct qui retourne toute les infos des dix films similaires à une description donnée\n",
        "def tf_idf(query, description):\n",
        "    query=preprocessing(query)\n",
        "    desc_clean=[]\n",
        "    for i in description:\n",
        "       desc_clean.append(preprocessing(i))\n",
        "    import numpy as np\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_desc = tfidf_vectorizer.fit_transform(desc_clean)\n",
        "    q = tfidf_vectorizer.transform([query])\n",
        "    cs = cosine_similarity(q, tfidf_desc)\n",
        "    res= cs[0]\n",
        "    result_list = [] #index\n",
        "    sim = [] #similarité\n",
        "    nb = 10\n",
        "    while nb > 0:\n",
        "        index = np.argmax(res)\n",
        "        result_list.append(index)\n",
        "        sim.append(res[index])\n",
        "        res[index] = 0\n",
        "        nb =nb - 1\n",
        "\n",
        "    print(\"les 10 films similaires à votre query est:\")\n",
        "    for i,j in zip(result_list,sim):\n",
        "            print(\"Titre :\"+titre[i])\n",
        "            s=int(j*100)\n",
        "            print(\"score de similarité :\"+str(s)+\"%\")\n",
        "            print(\"Genre :\"+genre[i])\n",
        "            print(\"Description :\"+desc[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnv4nv5-A4FE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "1052d731-e8ea-4a88-dee5-a1e2caf21ef8"
      },
      "source": [
        "tf_idf(desc[0],desc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "les 10 films similaires à votre query est:\n",
            "Titre :Titans\n",
            "score de similarité :100%\n",
            "Genre :Action\n",
            "Description :[\"Dick Grayson, alias Robin,\\xa0sort de l’ombre pour devenir le chef de file d’un groupe de nouveaux héros constitué notamment de Starfire, Raven ou encore Hawk et Dove. Peu à peu, il\\xa0s'affranchit de Batman pour devenir Nightwing....\"]\n",
            "Titre :Robin des bois\n",
            "score de similarité :10%\n",
            "Genre :Aventure\n",
            "Description :[\"Après 5 ans de croisades, Robin de Locksley rentre enfin chez lui pour découvrir avec effroi que les tyrannique Shérif de Nothingham et Guy de Gisbourne y règnent en maîtres absolus. Pour la population, tout n'est que désolation et misère...\", ' Afin de rétablir un ordre plus juste, Robin et ses compagnons Will Scarlett, Allan A Dale et Petit Jean investissent la forêt de Sherwood et deviennent des hors-la-loi... La légende de Robin des Bois est née.']\n",
            "Titre :Dick le rebelle\n",
            "score de similarité :10%\n",
            "Genre :Aventure\n",
            "Description :['Au 18ème siècle, les aventures de Dick Turpin, un bandit des grands chemins...']\n",
            "Titre :Rome\n",
            "score de similarité :8%\n",
            "Genre :Action\n",
            "Description :[\"Les destins de deux soldats romains et de leurs familles alors que la République Romaine est en train de s'effondrer en laissant peu à peu la place à un Empire.\"]\n",
            "Titre :Blue Dragon\n",
            "score de similarité :8%\n",
            "Genre :Aventure\n",
            "Description :[\"Les aventures de Shû, un jeune garçon qui découvre un jour qu'il possède une ombre qui peut se transformer en dragon bleu. Dans sa quête, il sera accompagné de six soldats de la Lumière, qui auront pour mission de réveiller également leur propre ombre afin de faire à nouveau régner la paix dans leur royaume.\"]\n",
            "Titre :Les Nouvelles Aventures de Robin des Bois\n",
            "score de similarité :8%\n",
            "Genre :Aventure\n",
            "Description :[\"Après bien des aventures, Robin des Bois est de retour en son pays. Il y découvre un peuple soumis à l'infâme Prince Jean, le frère du Roi Richard Coeur de Lion. Aidé de ses compagnons Petit Jean et Frère Tuck, Robin devient le défenseur de la veuve et de l'orphelin. Aussi rapide à l'arc qu'habile à l'épée, il va devoir affronter moult épreuves et innombrables ennemis en tous genres...\"]\n",
            "Titre :La Ligue des Justiciers : Nouvelle Génération\n",
            "score de similarité :8%\n",
            "Genre :Action\n",
            "Description :['', 'Les coéquipiers de membres de la Ligue de Justice se réunissent pour former la Young Justice sous la houlette de Batman. Ce dernier leur confie des missions pour venir à bout des vilains issus du groupe de La Lumière...', '']\n",
            "Titre :Private Practice\n",
            "score de similarité :7%\n",
            "Genre :Medical\n",
            "Description :[\"Après avoir échoué à se réconcilier avec les deux hommes de sa vie, le Dr Addison Montgomery quitte l'hôpital du Seattle Grace pour Los Angeles. Elle y retrouve des amis d'université, notamment Naomi et Sam, et accepte un poste dans leur clinique spécialisée dans la fertilité et la médecine parallèle. Peu à peu, sa vision idéaliste du mariage et des réussites professionnelles se dégrade, en constatant que même des conseillers conjugaux ne parviennent pas à faire fonctionner leur propre mariage...\"]\n",
            "Titre :The Boys\n",
            "score de similarité :7%\n",
            "Genre :Action\n",
            "Description :['Dans un monde fictif où les super-héros se sont laissés corrompre par la célébrité et la gloire et ont peu à peu révélé la part sombre de leur personnalité, une équipe de justiciers qui se fait appeler \"The Boys\" décide de passer à l\\'action et d\\'abattre ces super-héros autrefois appréciés de tous.']\n",
            "Titre :The Boys\n",
            "score de similarité :7%\n",
            "Genre :Drame\n",
            "Description :['Dans un monde fictif où les super-héros se sont laissés corrompre par la célébrité et la gloire et ont peu à peu révélé la part sombre de leur personnalité, une équipe de justiciers qui se fait appeler \"The Boys\" décide de passer à l\\'action et d\\'abattre ces super-héros autrefois appréciés de tous.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdp9g1lfs5me"
      },
      "source": [
        "#L'indice de similarité cosine (avec le resultat de TF) \n",
        "#une fct qui retourne toute les infos des dix films similaires à une description donnée\n",
        "def tf(query, description):\n",
        "    import numpy as np\n",
        "    query=preprocessing(query)\n",
        "    desc_clean=[]\n",
        "    for i in description:\n",
        "       desc_clean.append(preprocessing(i))\n",
        "    tf_vectorizer = CountVectorizer(binary=False, ngram_range=(1, 2))\n",
        "    tf_desc = tf_vectorizer.fit_transform(desc_clean)\n",
        "    q = tf_vectorizer.transform([query])\n",
        "    cs = cosine_similarity(q, tf_desc)\n",
        "    res= cs[0]\n",
        "    result_list = [] #index\n",
        "    sim = [] #similarité\n",
        "    nb = 10\n",
        "    while nb > 0:\n",
        "        index = np.argmax(res)\n",
        "        result_list.append(index)\n",
        "        sim.append(res[index])\n",
        "        res[index] = 0\n",
        "        nb =nb - 1\n",
        "\n",
        "    print(\"les 10 films similaires à votre query est:\")\n",
        "    for i,j in zip(result_list,sim):\n",
        "            print(\"Titre :\"+titre[i])\n",
        "            s=int(j*100)\n",
        "            print(\"score de similarité :\"+str(s)+\"%\")\n",
        "            print(\"Genre :\"+genre[i])\n",
        "            print(\"Description :\"+desc[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvCTRdXttbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "28019be8-7fc3-4bd8-b696-c0a2b8545a4b"
      },
      "source": [
        "tf(desc[0],desc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "les 10 films similaires à votre query est:\n",
            "Titre :Titans\n",
            "score de similarité :100%\n",
            "Genre :Action\n",
            "Description :[\"Dick Grayson, alias Robin,\\xa0sort de l’ombre pour devenir le chef de file d’un groupe de nouveaux héros constitué notamment de Starfire, Raven ou encore Hawk et Dove. Peu à peu, il\\xa0s'affranchit de Batman pour devenir Nightwing....\"]\n",
            "Titre :Rome\n",
            "score de similarité :11%\n",
            "Genre :Action\n",
            "Description :[\"Les destins de deux soldats romains et de leurs familles alors que la République Romaine est en train de s'effondrer en laissant peu à peu la place à un Empire.\"]\n",
            "Titre :Code 37, affaires de moeurs\n",
            "score de similarité :10%\n",
            "Genre :Police\n",
            "Description :['Hannah Maes est nommée capitaine au sein de la brigade des mœurs de Gand où elle dirige avec tempérament et finesse sa nouvelle équipe exclusivement masculine : Charles adepte des méthodes traditionnelles de la vieille école, Bob le macho et le jeune Kevin, spécialiste des nouvelles technologies. Malgré leur scepticisme, les enquêteurs découvrent peu à peu cette trentenaire d’un genre nouveau. On comprend rapidement que l’arrivée de Hannah n’est pas un hasard. Elle est revenue pour résoudre une affaire personnelle…']\n",
            "Titre :V Wars\n",
            "score de similarité :9%\n",
            "Genre :Drame\n",
            "Description :['Le Dr. Luther Swann voit sa vie basculer dans l\\'horreur le jour où son meilleur ami, Michael Fayne, se transforme en dangereux prédateur qui se nourrit de sang humain. Peu à peu, cette mystérieuse maladie se propage, divisant la société en deux camps : les gens \"normaux\" et les vampires. Swann entame une course contre la montre pour comprendre ce qu\\'il se passe et trouver un antidote, tandis que Fayne devient le leader des vampires...']\n",
            "Titre :The Boys\n",
            "score de similarité :9%\n",
            "Genre :Action\n",
            "Description :['Dans un monde fictif où les super-héros se sont laissés corrompre par la célébrité et la gloire et ont peu à peu révélé la part sombre de leur personnalité, une équipe de justiciers qui se fait appeler \"The Boys\" décide de passer à l\\'action et d\\'abattre ces super-héros autrefois appréciés de tous.']\n",
            "Titre :The Boys\n",
            "score de similarité :9%\n",
            "Genre :Drame\n",
            "Description :['Dans un monde fictif où les super-héros se sont laissés corrompre par la célébrité et la gloire et ont peu à peu révélé la part sombre de leur personnalité, une équipe de justiciers qui se fait appeler \"The Boys\" décide de passer à l\\'action et d\\'abattre ces super-héros autrefois appréciés de tous.']\n",
            "Titre :Overlord\n",
            "score de similarité :9%\n",
            "Genre :Action\n",
            "Description :['2138. \"Yggdrasil\", le plus célèbre MMORPG au monde est sur le point de fermer. Momonga, jeune geek, attend patiemment l’arrêt du jeu. Cependant, l’heure de fermeture passée, Momonga ne se déconnecte pas et constate que les personnages non jouables se retrouvent peu à peu dotés d’une conscience… Un nouveau monde est sur le point de faire son apparition.']\n",
            "Titre :Overlord\n",
            "score de similarité :9%\n",
            "Genre :Aventure\n",
            "Description :['2138. \"Yggdrasil\", le plus célèbre MMORPG au monde est sur le point de fermer. Momonga, jeune geek, attend patiemment l’arrêt du jeu. Cependant, l’heure de fermeture passée, Momonga ne se déconnecte pas et constate que les personnages non jouables se retrouvent peu à peu dotés d’une conscience… Un nouveau monde est sur le point de faire son apparition.']\n",
            "Titre :Valkyrien (UK)\n",
            "score de similarité :9%\n",
            "Genre :Medical\n",
            "Description :[\"A Londres, un chirurgien fonde un hôpital clandestin dans une station de métro désaffectée dans l'espoir de sauver sa femme d'une maladie incurable. Peu à peu, les patients qui ne peuvent recourir à des soins traditionnels affluent.\", 'Adaptation de la série norvégienne\\xa0', 'Valkyrien', '\\xa0(2017).', '']\n",
            "Titre :Zoo\n",
            "score de similarité :8%\n",
            "Genre :Drame\n",
            "Description :[\"A travers le globe, on observe des attaques soudaines d'animaux contre les Humains. Peu à peu, ces attaques se révèlent plus organisées et violentes. Voulant percer le mystère de ce phénomène, un jeune biologiste se lance dans une course contre la montre... pour sauver l'Humanité.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjVSpptGKrZo"
      },
      "source": [
        "Recherche par description en utilisant un algo supervisé"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuNCQGhNQ6Eq"
      },
      "source": [
        "Avec TF (CountVectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLJdATv4pHhx"
      },
      "source": [
        "#Générer la matrice des poids des descriptions pour appliquer les algos\n",
        "tf_vectorizer = CountVectorizer(binary=False)\n",
        "tf_desc = tf_vectorizer.fit_transform(desc_clean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y67iO4-foIqv"
      },
      "source": [
        "#Générer les deux échantillons d'entrainement et de test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tf_desc, genre, train_size = 0.75, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Cc2zTRQiYb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f0355c43-39e7-44fe-a795-3587cf7e96bd"
      },
      "source": [
        "#Appliquer LogisticRegression sur la matrice de poids en modifiant le parametre de régularisation C pour un bon score d'Accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_test, lr.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.34134615384615385\n",
            "Accuracy for C=0.05: 0.3269230769230769\n",
            "Accuracy for C=0.25: 0.33653846153846156\n",
            "Accuracy for C=0.5: 0.32211538461538464\n",
            "Accuracy for C=1: 0.32211538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4WRpzZsOkay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "932495b0-bf11-4b08-8925-3156269a3c91"
      },
      "source": [
        "#Appliquer SVC sur la matrice de poids en modifiant le parametre de régularisation C pour un bon score d'Accuracy\n",
        "from sklearn.svm import LinearSVC\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_test, svm.predict(X_test))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.35336538461538464\n",
            "Accuracy for C=0.05: 0.35096153846153844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.25: 0.31971153846153844\n",
            "Accuracy for C=0.5: 0.3173076923076923\n",
            "Accuracy for C=1: 0.31009615384615385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsljuvD6OkbE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c4d486-9947-4f11-c66f-31caf1ee8443"
      },
      "source": [
        "#Appliquer l'arbre de décision sur la matrice de poids \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "tr = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "tr.fit(X_train, y_train)\n",
        "print (\"Accuracy : %s\" % accuracy_score(y_test, tr.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.23076923076923078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evhZqlD_cP20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "85e995ad-4b87-4f64-b053-972ab6a60c47"
      },
      "source": [
        "#Appliquer KNN sur la matrice de poids en modifiant le parametre K pour un bon score d'Accuracy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k_epoch=range(1,400,10)\n",
        "for k in k_epoch:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    print (\"Accuracy for K=%s: %s\" % (k, accuracy_score(y_test, knn.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K=1: 0.1346153846153846\n",
            "Accuracy for K=11: 0.15384615384615385\n",
            "Accuracy for K=21: 0.17067307692307693\n",
            "Accuracy for K=31: 0.17307692307692307\n",
            "Accuracy for K=41: 0.16346153846153846\n",
            "Accuracy for K=51: 0.18028846153846154\n",
            "Accuracy for K=61: 0.20432692307692307\n",
            "Accuracy for K=71: 0.22596153846153846\n",
            "Accuracy for K=81: 0.2283653846153846\n",
            "Accuracy for K=91: 0.22596153846153846\n",
            "Accuracy for K=101: 0.23076923076923078\n",
            "Accuracy for K=111: 0.2403846153846154\n",
            "Accuracy for K=121: 0.24519230769230768\n",
            "Accuracy for K=131: 0.24278846153846154\n",
            "Accuracy for K=141: 0.23798076923076922\n",
            "Accuracy for K=151: 0.23557692307692307\n",
            "Accuracy for K=161: 0.23557692307692307\n",
            "Accuracy for K=171: 0.23557692307692307\n",
            "Accuracy for K=181: 0.23076923076923078\n",
            "Accuracy for K=191: 0.23317307692307693\n",
            "Accuracy for K=201: 0.23557692307692307\n",
            "Accuracy for K=211: 0.23557692307692307\n",
            "Accuracy for K=221: 0.23557692307692307\n",
            "Accuracy for K=231: 0.23557692307692307\n",
            "Accuracy for K=241: 0.23076923076923078\n",
            "Accuracy for K=251: 0.23798076923076922\n",
            "Accuracy for K=261: 0.23317307692307693\n",
            "Accuracy for K=271: 0.2403846153846154\n",
            "Accuracy for K=281: 0.2403846153846154\n",
            "Accuracy for K=291: 0.23798076923076922\n",
            "Accuracy for K=301: 0.2548076923076923\n",
            "Accuracy for K=311: 0.23798076923076922\n",
            "Accuracy for K=321: 0.2403846153846154\n",
            "Accuracy for K=331: 0.23798076923076922\n",
            "Accuracy for K=341: 0.2403846153846154\n",
            "Accuracy for K=351: 0.25\n",
            "Accuracy for K=361: 0.23557692307692307\n",
            "Accuracy for K=371: 0.23798076923076922\n",
            "Accuracy for K=381: 0.25240384615384615\n",
            "Accuracy for K=391: 0.24759615384615385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF2hjJaprd67"
      },
      "source": [
        "#quantifier les label pour appliquer naive_bayes\n",
        "label=[]\n",
        "for i in genre:\n",
        "  if i == \"Action\" :\n",
        "    label.append(1)\n",
        "  if i == \"Aventure\" :\n",
        "    label.append(2)\n",
        "  if i == \"Comedie\" :\n",
        "    label.append(3)\n",
        "  if i == \"Drame\" :\n",
        "    label.append(4)\n",
        "  if i == \"Medical\" :\n",
        "    label.append(5)  \n",
        "  if i == \"Police\" :\n",
        "    label.append(6)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tf_desc, label, train_size = 0.75, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1XM8dkKh6F8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db77a011-d952-4e6e-fcc2-6b337860688a"
      },
      "source": [
        "#Appliquer naive_bayes sur la matrice de poids \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "print (\"Accuracy : %s\" % accuracy_score(y_test, naive_bayes.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.3317307692307692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEa7aH1ERBQ0"
      },
      "source": [
        "Avec TfIdf (TfidfVectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB7wSVc1R3qS"
      },
      "source": [
        "#Générer la matrice des poids des descriptions pour appliquer les algos\n",
        "tfidf_vectorizer = TfidfVectorizer(binary=False)\n",
        "tfidf_desc = tfidf_vectorizer.fit_transform(desc_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFsjDC0zR4Gv"
      },
      "source": [
        "#Générer les deux échantillons d'entrainement et de test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_desc, genre, train_size = 0.75, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtwSDI0O60K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5aacbc07-7b73-4deb-cb95-8a8fc8f09f8e"
      },
      "source": [
        "#Appliquer LogisticRegression sur la matrice de poids en modifiant le parametre de régularisation C pour un bon score d'Accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_test, lr.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.18028846153846154\n",
            "Accuracy for C=0.05: 0.2764423076923077\n",
            "Accuracy for C=0.25: 0.3389423076923077\n",
            "Accuracy for C=0.5: 0.3581730769230769\n",
            "Accuracy for C=1: 0.3581730769230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qch3x10O60U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cdb90df2-49dd-4b98-b1ba-08f3d461b930"
      },
      "source": [
        "#Appliquer SVC sur la matrice de poids en modifiant le parametre de régularisation C pour un bon score d'Accuracy\n",
        "from sklearn.svm import LinearSVC\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_test, svm.predict(X_test))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.29086538461538464\n",
            "Accuracy for C=0.05: 0.38221153846153844\n",
            "Accuracy for C=0.25: 0.3701923076923077\n",
            "Accuracy for C=0.5: 0.36538461538461536\n",
            "Accuracy for C=1: 0.36538461538461536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBrWq7Y0O60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61e9b10-3159-4769-8358-11d74efe02b2"
      },
      "source": [
        "#Appliquer l'arbre de décision sur la matrice de poids\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "tr = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "tr.fit(X_train, y_train)\n",
        "print (\"Accuracy : %s\" % accuracy_score(y_test, tr.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.2283653846153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyGhTeK0WpWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "2ce9e90e-de6c-4b90-b3c9-5976db6bf163"
      },
      "source": [
        "#Appliquer KNN sur la matrice de poids en modifiant le parametre K pour un bon score d'Accuracy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k_epoch=range(1,400,10)\n",
        "for k in k_epoch:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    print (\"Accuracy for K=%s: %s\" % (k, accuracy_score(y_test, knn.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K=1: 0.0985576923076923\n",
            "Accuracy for K=11: 0.16346153846153846\n",
            "Accuracy for K=21: 0.15384615384615385\n",
            "Accuracy for K=31: 0.16826923076923078\n",
            "Accuracy for K=41: 0.15865384615384615\n",
            "Accuracy for K=51: 0.24519230769230768\n",
            "Accuracy for K=61: 0.2668269230769231\n",
            "Accuracy for K=71: 0.25961538461538464\n",
            "Accuracy for K=81: 0.27884615384615385\n",
            "Accuracy for K=91: 0.3004807692307692\n",
            "Accuracy for K=101: 0.33653846153846156\n",
            "Accuracy for K=111: 0.35336538461538464\n",
            "Accuracy for K=121: 0.3629807692307692\n",
            "Accuracy for K=131: 0.3894230769230769\n",
            "Accuracy for K=141: 0.40865384615384615\n",
            "Accuracy for K=151: 0.4230769230769231\n",
            "Accuracy for K=161: 0.4326923076923077\n",
            "Accuracy for K=171: 0.44711538461538464\n",
            "Accuracy for K=181: 0.43990384615384615\n",
            "Accuracy for K=191: 0.4495192307692308\n",
            "Accuracy for K=201: 0.46153846153846156\n",
            "Accuracy for K=211: 0.46875\n",
            "Accuracy for K=221: 0.4495192307692308\n",
            "Accuracy for K=231: 0.4495192307692308\n",
            "Accuracy for K=241: 0.4375\n",
            "Accuracy for K=251: 0.45913461538461536\n",
            "Accuracy for K=261: 0.45913461538461536\n",
            "Accuracy for K=271: 0.45913461538461536\n",
            "Accuracy for K=281: 0.4495192307692308\n",
            "Accuracy for K=291: 0.4543269230769231\n",
            "Accuracy for K=301: 0.45913461538461536\n",
            "Accuracy for K=311: 0.4567307692307692\n",
            "Accuracy for K=321: 0.44711538461538464\n",
            "Accuracy for K=331: 0.43990384615384615\n",
            "Accuracy for K=341: 0.4495192307692308\n",
            "Accuracy for K=351: 0.43028846153846156\n",
            "Accuracy for K=361: 0.4110576923076923\n",
            "Accuracy for K=371: 0.4110576923076923\n",
            "Accuracy for K=381: 0.4206730769230769\n",
            "Accuracy for K=391: 0.4206730769230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtkJVvl9EFu8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tf_desc, label, train_size = 0.75, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f-SGn-wdsn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a34bcd27-2a4e-4d78-c703-5ebc67da17ef"
      },
      "source": [
        "#Appliquer naive_bayes sur la matrice de poids\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "print (\"Accuracy : %s\" % accuracy_score(y_test, naive_bayes.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.3317307692307692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUFFx8scCIe_"
      },
      "source": [
        "Recherche par genre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4IQ_urBCLQX"
      },
      "source": [
        "#fct qui génére un score(moyenne des avis) d'un film donné en se basant sur l'analyse de sentiment des avis\n",
        "def scorer_film(tit):\n",
        "  res=[]\n",
        "  sc=0\n",
        "  from textblob import TextBlob\n",
        "  from textblob import Blobber\n",
        "  from textblob_fr import PatternTagger, PatternAnalyzer\n",
        "  tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "  for i in range(0,len(titreR)):\n",
        "       if titreR[i] == tit:\n",
        "           text = tb(u\"\"+avis[i])\n",
        "           res.append(text.sentiment[0])\n",
        "       elif len(res) != 0.0:\n",
        "           sc = sum(res)/len(res)\n",
        "  return round(sc,2)\n",
        "\n",
        "#fct qui retourne les film d'un genre donné ordonné par un score d'analyse de sentiment\n",
        "def scorer_par_genre(g):\n",
        "  import pandas as pd\n",
        "  film=[]\n",
        "  score=[]\n",
        "  for i in range(0,len(genre)):\n",
        "    if (genre[i] == g) and (scorer_film(titre[i]) !=0.0) :\n",
        "         film.append(titre[i])\n",
        "         score.append(int(scorer_film(titre[i])*100))\n",
        "  d={\"Titre\":film,\"Score\":score}\n",
        "  df=pd.DataFrame(d)\n",
        "  df=df.dropna(axis=0)\n",
        "  df=df.sort_values(by=['Score'], ascending=False)\n",
        "  df=df.iloc[0:10,]\n",
        "  df=df.reset_index(drop=True)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cro_7ssei87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d3d591fe-e79a-4d45-e40d-8a65589fa54f"
      },
      "source": [
        "scorer_par_genre(\"Action\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titre</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Halo: The Fall Of Reach</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Marvel's Spider-Man</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ken : Fist of the Blue Sky Regenesis</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chicago Fire</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le Rebelle</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>24 : La conspiration</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Simon et Simon</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hunter X Hunter (2011)</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kengan Ashura</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Dragons : par-delà les rives</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Titre  Score\n",
              "0               Halo: The Fall Of Reach     70\n",
              "1                   Marvel's Spider-Man     62\n",
              "2  Ken : Fist of the Blue Sky Regenesis     61\n",
              "3                          Chicago Fire     40\n",
              "4                            Le Rebelle     39\n",
              "5                  24 : La conspiration     36\n",
              "6                        Simon et Simon     36\n",
              "7                Hunter X Hunter (2011)     34\n",
              "8                         Kengan Ashura     34\n",
              "9          Dragons : par-delà les rives     34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXmBNNAaWX8f"
      },
      "source": [
        "#Le film le plus similaire a une description donnée si la requete entrante est une discription ou une partie de cette dérnière\n",
        "def sim_desc(query):\n",
        "  query=preprocessing(query)\n",
        "  import numpy as np\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  tfidf_desc = tfidf_vectorizer.fit_transform(desc_clean)\n",
        "  q = tfidf_vectorizer.transform([query])\n",
        "  cs = cosine_similarity(q, tfidf_desc)\n",
        "  ind=np.argmax(cs[0])\n",
        "  print(\"Titre  : \"+titre[ind])\n",
        "  print(\"Description  : \"+desc[ind])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Lqgn4V7-O-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9864521-385d-44d9-c0d4-08ba1ceb0b51"
      },
      "source": [
        "sim_desc(\"guerre problème\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Titre  : L'Enfer du devoir\n",
            "Description  : [\"Au coeur de la guerre du Vietnam avec une unité d'infanterie de l'armée américaine...\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF7TYav4cAE0"
      },
      "source": [
        "#Les bon films ordonés par analyse de sentiment des avis\n",
        "def positive_film():\n",
        "  res=[]\n",
        "  ress=[]\n",
        "  for i in titre:\n",
        "    res.append(i)\n",
        "    ress.append(int(scorer_film(i)*100))\n",
        "  d={\"Titre\":res,\"Score\":ress}\n",
        "  df=pd.DataFrame(d)\n",
        "  df=df.dropna(axis=0)\n",
        "  df=df.sort_values(by=['Score'], ascending=False)\n",
        "  df=df.iloc[0:10,]\n",
        "  df=df.reset_index(drop=True)\n",
        "  df=df.drop_duplicates()\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjTqNosnd23B"
      },
      "source": [
        "#Les mauvais films ordonés par analyse de sentiment des avis\n",
        "def negative_film():\n",
        "  res=[]\n",
        "  ress=[]\n",
        "  for i in titre:\n",
        "    res.append(i)\n",
        "    ress.append(int(scorer_film(i)*100))\n",
        "  d={\"Titre\":res,\"Score\":ress}\n",
        "  df=pd.DataFrame(d)\n",
        "  df=df.dropna(axis=0)\n",
        "  df=df.sort_values(by=['Score'])\n",
        "  df=df.iloc[0:10,]\n",
        "  df=df.reset_index(drop=True)\n",
        "  df=df.drop_duplicates()\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOjH-X-lPefJ"
      },
      "source": [
        "Recherche générale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLO5CuHuPiTv"
      },
      "source": [
        "#fct qui retourne:\n",
        "######Le titre si la requete entrante est un nom d'un film\n",
        "######Les différentes films d'un genre donné grouper par analyse des avis si  la requete entrante est un genre\n",
        "######Le film le plus similaire a une description donnée si la requete entrante est une discription ou une partie de cette dérnière\n",
        "######Les bon films ordonés par analyse de sentiment des avis si la requete entrante est un avis positif \n",
        "######Les mauvais films ordonés par analyse de sentiment des avis si la requete entrante est un avis négatif\n",
        "def recherche_generale(requete):\n",
        "  from textblob import TextBlob\n",
        "  from textblob import Blobber\n",
        "  from textblob_fr import PatternTagger, PatternAnalyzer\n",
        "  tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "  text = tb(u\"\"+requete)\n",
        "  res=text.sentiment\n",
        "  if res[1] == 0.0 :\n",
        "    for i in titre:\n",
        "      if i == requete :\n",
        "#        print(\"recherche par titre\")\n",
        "        return recherche_par_titre_AS(requete)\n",
        "    for i in list(set(genre)):\n",
        "      if i == requete :\n",
        "#        print(\"recherche par genre\")\n",
        "        return  scorer_par_genre(requete) \n",
        "  elif (res[0] < 0.3 and res[0] > 0) or (res[0] > -0.3 and res[0] < 0) :\n",
        "#    print(\"recherche par description\")\n",
        "    return sim_desc(requete)\n",
        "  elif res[0] > 0.3 :\n",
        "#    print(\"Positivité\")\n",
        "    return positive_film()\n",
        "  elif (res[0] < int(-1*0.3)) :\n",
        "#    print(\"Négativité\")\n",
        "    return negative_film()\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzZXvslrkRJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "579e5783-f8c1-40b3-bfc1-ac832da33e8e"
      },
      "source": [
        "desc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\"Dick Grayson, alias Robin,\\\\xa0sort de l’ombre pour devenir le chef de file d’un groupe de nouveaux héros constitué notamment de Starfire, Raven ou encore Hawk et Dove. Peu à peu, il\\\\xa0s\\'affranchit de Batman pour devenir Nightwing....\"]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pml3s0XYSw9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ae2b5e86-320e-41dd-bb19-de28f1edb710"
      },
      "source": [
        "recherche_generale(\"bon film\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titre</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>October Faction</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>El Síndrome de Ulises</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Halo: The Fall Of Reach</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carmen Sandiego</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marvel's Spider-Man</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ken : Fist of the Blue Sky Regenesis</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Le Pacte</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Les Aventures de Sinbad</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Alliances &amp; trahisons</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Pagan Peak</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Titre  Score\n",
              "0                       October Faction     72\n",
              "1                 El Síndrome de Ulises     70\n",
              "2               Halo: The Fall Of Reach     70\n",
              "3                       Carmen Sandiego     65\n",
              "4                   Marvel's Spider-Man     62\n",
              "5  Ken : Fist of the Blue Sky Regenesis     61\n",
              "6                              Le Pacte     51\n",
              "7               Les Aventures de Sinbad     50\n",
              "8                 Alliances & trahisons     47\n",
              "9                            Pagan Peak     47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}